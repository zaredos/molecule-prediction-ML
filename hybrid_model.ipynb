{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 3\n",
    "The prediction of molecular properties is an important task in drug discovery. The molecules' atomic composition and arrangement can already tell us a lot about their biological behavior. Each 2D molecule can be represented as a graph, where the nodes are atoms connected by edges corresponding to chemical bonds. The prediction of molecular properties can be formulized as a graph classification task, and graph neural network is usually applied for making graph-level prediction.\n",
    "\n",
    "In this project, you need develop a model for predicting the toxicity of new molecules. This notebook provides a sample pipeline that establishes a baseline. It is expected that your methods should outperform this baseline. You are strongly encouraged to think about designing more powerful models, finetuning hyperparameters, developing better training strategies, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch_geometric in e:\\llama\\work\\.conda\\lib\\site-packages (2.4.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\harry\\appdata\\roaming\\python\\python310\\site-packages (from torch_geometric) (4.64.1)\n",
      "Requirement already satisfied: numpy in e:\\llama\\work\\.conda\\lib\\site-packages (from torch_geometric) (1.26.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\harry\\appdata\\roaming\\python\\python310\\site-packages (from torch_geometric) (1.10.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\harry\\appdata\\roaming\\python\\python310\\site-packages (from torch_geometric) (3.1.2)\n",
      "Requirement already satisfied: requests in c:\\users\\harry\\appdata\\roaming\\python\\python310\\site-packages (from torch_geometric) (2.28.2)\n",
      "Requirement already satisfied: pyparsing in c:\\users\\harry\\appdata\\roaming\\python\\python310\\site-packages (from torch_geometric) (3.0.9)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\harry\\appdata\\roaming\\python\\python310\\site-packages (from torch_geometric) (1.2.2)\n",
      "Requirement already satisfied: psutil>=5.8.0 in e:\\llama\\work\\.conda\\lib\\site-packages (from torch_geometric) (5.9.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\harry\\appdata\\roaming\\python\\python310\\site-packages (from jinja2->torch_geometric) (2.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\harry\\appdata\\roaming\\python\\python310\\site-packages (from requests->torch_geometric) (3.0.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\harry\\appdata\\roaming\\python\\python310\\site-packages (from requests->torch_geometric) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\harry\\appdata\\roaming\\python\\python310\\site-packages (from requests->torch_geometric) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\harry\\appdata\\roaming\\python\\python310\\site-packages (from requests->torch_geometric) (2022.12.7)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\harry\\appdata\\roaming\\python\\python310\\site-packages (from scikit-learn->torch_geometric) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\harry\\appdata\\roaming\\python\\python310\\site-packages (from scikit-learn->torch_geometric) (3.1.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\harry\\appdata\\roaming\\python\\python310\\site-packages (from tqdm->torch_geometric) (0.4.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\harry\\appdata\\roaming\\python\\python310\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\harry\\appdata\\roaming\\python\\python310\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\harry\\appdata\\roaming\\python\\python310\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\harry\\appdata\\roaming\\python\\python310\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 23.1.2 -> 23.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: rdkit-pypi in e:\\llama\\work\\.conda\\lib\\site-packages (2022.9.5)\n",
      "Requirement already satisfied: numpy in e:\\llama\\work\\.conda\\lib\\site-packages (from rdkit-pypi) (1.26.2)\n",
      "Requirement already satisfied: Pillow in c:\\users\\harry\\appdata\\roaming\\python\\python310\\site-packages (from rdkit-pypi) (9.4.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\harry\\appdata\\roaming\\python\\python310\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\harry\\appdata\\roaming\\python\\python310\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\harry\\appdata\\roaming\\python\\python310\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\harry\\appdata\\roaming\\python\\python310\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 23.1.2 -> 23.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# New these two packages\n",
    "!pip install torch_geometric\n",
    "!pip install rdkit-pypi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset preparation and train-valid splitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\harry\\AppData\\Roaming\\Python\\Python310\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of training set: 6264\n",
      "Size of validation set: 783\n",
      "Size of test set: 784\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch_geometric\n",
    "import numpy as np\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.data import DataLoader\n",
    "from torch_geometric.datasets import MoleculeNet\n",
    "import pickle\n",
    "\n",
    "# Load datasets. The training and validation sets contain both molecules and their property labels. The test set only contain molecules.\n",
    "# There are 12 property tasks for prediction. Some properties labels are missing (i.e., nan). You can ignore them.\n",
    "train_dataset = torch.load(\"train_data.pt\")\n",
    "valid_dataset = torch.load(\"valid_data.pt\")\n",
    "test_dataset = torch.load(\"test_data.pt\")\n",
    "\n",
    "print(f'Size of training set: {len(train_dataset)}')\n",
    "print(f'Size of validation set: {len(valid_dataset)}')\n",
    "print(f'Size of test set: {len(test_dataset)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New Features\n",
    "First, we get features that are not included and add them to the original feature datasets.<br>\n",
    "Below is some testing for each of the Descriptors in the rdkit Chem module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.45\n",
      "0.7\n",
      "0.9\n"
     ]
    }
   ],
   "source": [
    "from rdkit import Chem\n",
    "from rdkit.Chem import Descriptors as desc\n",
    "\n",
    "print(desc.FpDensityMorgan1(Chem.MolFromSmiles(train_dataset[1].smiles)))\n",
    "print(desc.FpDensityMorgan2(Chem.MolFromSmiles(train_dataset[1].smiles)))\n",
    "print(desc.FpDensityMorgan3(Chem.MolFromSmiles(train_dataset[1].smiles)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Hybrid Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import GCNConv, global_mean_pool as gap, BatchNorm, Linear\n",
    "import torch.nn.functional as F \n",
    "from torch.nn import Linear\n",
    "\n",
    "def reshape_tensor(tensor):\n",
    "    reshaped_tensor = tensor.view(16, 32)\n",
    "    return reshaped_tensor\n",
    "\n",
    "\n",
    "class AtomEncoder(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super(AtomEncoder, self).__init__()\n",
    "\n",
    "        self.embeddings = torch.nn.ModuleList()\n",
    "\n",
    "        for i in range(9):\n",
    "            self.embeddings.append(torch.nn.Embedding(100, hidden_channels))\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        for embedding in self.embeddings:\n",
    "            embedding.reset_parameters()\n",
    "\n",
    "    def forward(self, x):\n",
    "        if x.dim() == 1:\n",
    "            x = x.unsqueeze(1)\n",
    "\n",
    "        out = 0\n",
    "        for i in range(x.size(1)):\n",
    "            out += self.embeddings[i](x[:, i])\n",
    "        return out\n",
    "\n",
    "# Our Encoder (does not use the edge_index or embeddings, can get about 65% accuracy)\n",
    "class ModifiedAtomEncoder(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels, num_node_features):\n",
    "        super(ModifiedAtomEncoder, self).__init__()\n",
    "\n",
    "        self.linear_layers = torch.nn.ModuleList()\n",
    "\n",
    "        for i in range(num_node_features):\n",
    "            self.linear_layers.append(torch.nn.Linear(1, hidden_channels))\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        for linear in self.linear_layers:\n",
    "            torch.nn.init.xavier_uniform_(linear.weight)\n",
    "            torch.nn.init.zeros_(linear.bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if x.dim() == 1:\n",
    "            x = x.unsqueeze(1)\n",
    "\n",
    "        out = 0\n",
    "        for i in range(x.size(1)):\n",
    "            out += self.linear_layers[i](x[:, i:i+1])\n",
    "        return out\n",
    "\n",
    "\n",
    "class GCN_noGraph(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels, num_node_features, num_classes):\n",
    "        super(GCN_noGraph, self).__init__()\n",
    "        torch.manual_seed(42)\n",
    "        self.emb = AtomEncoder(hidden_channels=32, num_node_features=num_node_features)\n",
    "        self.lin = Linear(hidden_channels, num_classes)\n",
    "\n",
    "    def forward(self, batch):\n",
    "        x, batch_size = batch.descriptors, batch.batch\n",
    "        x = self.emb(x)\n",
    "\n",
    "        # 2. Readout layer\n",
    "        x = gap(x, batch_size)  # [batch_size, hidden_channels]\n",
    "        # 3. Apply a final classifier\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.lin(x)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "  \n",
    "# The given model (uses the edge_index, can get about 74% accuracy)\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels, num_node_features, num_classes):\n",
    "        super(GCN, self).__init__()\n",
    "        torch.manual_seed(42)\n",
    "        self.emb = AtomEncoder(hidden_channels=32)\n",
    "        self.conv1 = GCNConv(hidden_channels, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
    "        self.conv3 = GCNConv(hidden_channels, hidden_channels)\n",
    "        self.lin = Linear(hidden_channels, num_classes)\n",
    "\n",
    "    def forward(self, batch):\n",
    "        x, edge_index, batch_size = batch.x, batch.edge_index, batch.batch\n",
    "        x = self.emb(x)\n",
    "        \n",
    "        # 1. Obtain node embeddings\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = self.conv3(x, edge_index)\n",
    "\n",
    "        # 2. Readout layer\n",
    "        x = gap(x, batch_size)  # [batch_size, hidden_channels]\n",
    "        # 3. Apply a final classifier\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.lin(x)\n",
    "        return x\n",
    "  \n",
    "# Hybrid model (uses both the edge_index and the non-graph features)\n",
    "\n",
    "class HybridModel(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels, num_node_features, num_classes, num_features_nongraph):\n",
    "        super(HybridModel, self).__init__()\n",
    "\n",
    "        # Graph-based Classifier\n",
    "        self.emb = AtomEncoder(hidden_channels=hidden_channels)\n",
    "        self.non_graph_emb = ModifiedAtomEncoder(hidden_channels=hidden_channels, num_node_features=num_features_nongraph)\n",
    "        self.conv1 = GCNConv(hidden_channels, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
    "        self.conv3 = GCNConv(hidden_channels, hidden_channels)\n",
    "        self.lin_graph = Linear(hidden_channels, hidden_channels)\n",
    "\n",
    "        # Non-graph Classifier\n",
    "        self.fc1 = torch.nn.Linear(hidden_channels, hidden_channels)\n",
    "        self.fc2 = torch.nn.Linear(hidden_channels, hidden_channels)\n",
    "\n",
    "        # Combined layers\n",
    "        self.fc3 = torch.nn.Linear(2 * hidden_channels, hidden_channels)  # Combining graph and non-graph outputs\n",
    "        self.fc4 = torch.nn.Linear(hidden_channels, num_classes)\n",
    "\n",
    "    def forward(self, batch):\n",
    "        # Graph component (x is the graph features, y is the non-graph features)\n",
    "        x, edge_index, batch_index, y = batch.x, batch.edge_index, batch.batch, batch.descriptors\n",
    "\n",
    "        x = self.emb(x)\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = F.relu(self.conv2(x, edge_index))\n",
    "        x = F.relu(self.conv3(x, edge_index))\n",
    "        print('1', x.shape)\n",
    "        x = gap(x, batch_index)  # [batch_size, hidden_channels]\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.lin_graph(x)\n",
    "        x = x.float() # Convert to float for concatenation\n",
    "\n",
    "        # Non-graph component\n",
    "        y = self.non_graph_emb(y)\n",
    "        print('2', y.shape)\n",
    "        y = F.relu(self.fc1(y))\n",
    "        y = gap(y, batch_index)  # [batch_size, hidden_channels]\n",
    "        # 3. Apply a final classifier\n",
    "        y = F.dropout(y, p=0.5, training=self.training)\n",
    "        y = self.fc2(y)\n",
    "\n",
    "        # Combine\n",
    "        z = torch.cat([x, y], dim=1)\n",
    "        z = F.relu(self.fc3(z))\n",
    "        z = self.fc4(z)\n",
    "\n",
    "        return z\n",
    "\n",
    "def reshape_tensor(tensor):\n",
    "    reshaped_tensor = tensor.view(16, 32)\n",
    "    return reshaped_tensor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\harry\\AppData\\Local\\Temp\\ipykernel_51428\\243742278.py:25: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  new_features = torch.tensor(new_features).to(torch.float32)\n",
      "[21:47:35] WARNING: not removing hydrogen atom without neighbors\n"
     ]
    }
   ],
   "source": [
    "# Put all of the datasets into one list\n",
    "datasets = [train_dataset, valid_dataset, test_dataset]\n",
    "\n",
    "for dataset in datasets:\n",
    "    for graph in dataset:\n",
    "        mol = Chem.MolFromSmiles(graph.smiles)\n",
    "        new_features = torch.tensor([\n",
    "            desc.FpDensityMorgan1(mol),\n",
    "            desc.FpDensityMorgan2(mol),\n",
    "            desc.FpDensityMorgan3(mol),\n",
    "            desc.HeavyAtomMolWt(mol),\n",
    "            desc.NumHAcceptors(mol),\n",
    "            desc.NHOHCount(mol),\n",
    "            desc.Kappa3(mol),\n",
    "            desc.NOCount(mol),\n",
    "            desc.HallKierAlpha(mol),\n",
    "            desc.MinEStateIndex(mol),\n",
    "            desc.MolWt(mol),\n",
    "            desc.BalabanJ(mol),\n",
    "            desc.MolLogP(mol),\n",
    "            desc.PEOE_VSA6(mol),\n",
    "            desc.SlogP_VSA2(mol),\n",
    "            desc.SMR_VSA7(mol),\n",
    "        ])\n",
    "        new_features = torch.tensor(new_features).to(torch.float32)\n",
    "        graph.descriptors = new_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([  1.0000,   1.1818,   1.1818, 197.9630,   3.0000,   5.0000,   2.0995,\n",
      "          7.0000,   0.2600,  -5.1977, 206.0270,   5.0795,  -0.9922,   0.0000,\n",
      "         29.7634,   0.0000])\n",
      "torch.Size([16])\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset[0].descriptors)\n",
    "print(train_dataset[1].descriptors.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a model\n",
    "num_node_features = train_dataset[0].x.shape[0]\n",
    "num_features_nongraph = train_dataset[0].descriptors.shape[0]\n",
    "model = HybridModel(32, num_node_features, 12, num_features_nongraph)\n",
    "\n",
    "# loss function and optimizer\n",
    "import torch.optim as optim\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "criterion = torch.nn.BCEWithLogitsLoss(reduction = \"none\")\n",
    "\n",
    "# Create DataLoaders\n",
    "from torch_geometric.data import DataLoader\n",
    "\n",
    "batch_size=32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train and eval function\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def train(model, device, loader, optimizer):\n",
    "    model.train()\n",
    "\n",
    "    for step, batch in enumerate(loader):\n",
    "        batch = batch.to(device)\n",
    "        pred = model(batch)\n",
    "        y = batch.y.view(pred.shape).to(torch.float64)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        ## ignore nan targets (unlabeled) when computing training loss.\n",
    "        is_labeled = batch.y == batch.y\n",
    "        loss = criterion(pred.to(torch.float32)[is_labeled], batch.y.to(torch.float32)[is_labeled]).mean()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "def eval(model, device, loader):\n",
    "    model.eval()\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    # For every batch in test loader\n",
    "    for batch in loader:\n",
    "\n",
    "        batch = batch.to(device)\n",
    "        if batch.x.shape[0] == 1:\n",
    "            pass\n",
    "        else:\n",
    "            with torch.no_grad():\n",
    "                pred = model(batch)\n",
    "\n",
    "            y_true.append(batch.y.view(pred.shape))\n",
    "            y_pred.append(pred)\n",
    "\n",
    "    y_true = torch.cat(y_true, dim = 0).numpy()\n",
    "    y_pred = torch.cat(y_pred, dim = 0).numpy()\n",
    "    # Compute the ROC - AUC score and store as history\n",
    "    rocauc_list = []\n",
    "\n",
    "    for i in range(y_true.shape[1]):\n",
    "        #AUC is only defined when there is at least one positive data.\n",
    "        if np.sum(y_true[:,i] == 1) > 0 and np.sum(y_true[:,i] == 0) > 0:\n",
    "            # ignore nan values\n",
    "            is_labeled = y_true[:,i] == y_true[:,i]\n",
    "            rocauc_list.append(roc_auc_score(y_true[is_labeled,i], y_pred[is_labeled,i]))\n",
    "\n",
    "    if len(rocauc_list) == 0:\n",
    "        raise RuntimeError('No positively labeled data available. Cannot compute ROC-AUC.')\n",
    "\n",
    "    return {'rocauc': sum(rocauc_list)/len(rocauc_list)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training...\n",
      "<class '__main__.HybridModel'>\n",
      "====epoch 1\n",
      "2 torch.Size([512, 32])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected index [590] to be smaller than self [32] apart from dimension 0 and to be smaller size than src [512]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mg:\\CS149\\hybrid_model.ipynb Cell 17\u001b[0m line \u001b[0;36m9\n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/CS149/hybrid_model.ipynb#X22sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m====epoch \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(epoch))\n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/CS149/hybrid_model.ipynb#X22sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39m# training\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/g%3A/CS149/hybrid_model.ipynb#X22sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m train(model, device, train_loader, optimizer)\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/CS149/hybrid_model.ipynb#X22sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39m# evaluating\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/CS149/hybrid_model.ipynb#X22sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m train_acc \u001b[39m=\u001b[39m \u001b[39meval\u001b[39m(model, device, train_loader)\n",
      "\u001b[1;32mg:\\CS149\\hybrid_model.ipynb Cell 17\u001b[0m line \u001b[0;36m9\n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/CS149/hybrid_model.ipynb#X22sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mfor\u001b[39;00m step, batch \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(loader):\n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/CS149/hybrid_model.ipynb#X22sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     batch \u001b[39m=\u001b[39m batch\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/g%3A/CS149/hybrid_model.ipynb#X22sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     pred \u001b[39m=\u001b[39m model(batch)\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/CS149/hybrid_model.ipynb#X22sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     y \u001b[39m=\u001b[39m batch\u001b[39m.\u001b[39my\u001b[39m.\u001b[39mview(pred\u001b[39m.\u001b[39mshape)\u001b[39m.\u001b[39mto(torch\u001b[39m.\u001b[39mfloat64)\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/CS149/hybrid_model.ipynb#X22sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     optimizer\u001b[39m.\u001b[39mzero_grad()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32mg:\\CS149\\hybrid_model.ipynb Cell 17\u001b[0m line \u001b[0;36m1\n\u001b[0;32m    <a href='vscode-notebook-cell:/g%3A/CS149/hybrid_model.ipynb#X22sZmlsZQ%3D%3D?line=135'>136</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m2\u001b[39m\u001b[39m'\u001b[39m, y\u001b[39m.\u001b[39mshape)\n\u001b[0;32m    <a href='vscode-notebook-cell:/g%3A/CS149/hybrid_model.ipynb#X22sZmlsZQ%3D%3D?line=136'>137</a>\u001b[0m y \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfc1(y))\n\u001b[1;32m--> <a href='vscode-notebook-cell:/g%3A/CS149/hybrid_model.ipynb#X22sZmlsZQ%3D%3D?line=137'>138</a>\u001b[0m y \u001b[39m=\u001b[39m gap(y, batch_index)  \u001b[39m# [batch_size, hidden_channels]\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/g%3A/CS149/hybrid_model.ipynb#X22sZmlsZQ%3D%3D?line=138'>139</a>\u001b[0m \u001b[39m# 3. Apply a final classifier\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/g%3A/CS149/hybrid_model.ipynb#X22sZmlsZQ%3D%3D?line=139'>140</a>\u001b[0m y \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mdropout(y, p\u001b[39m=\u001b[39m\u001b[39m0.5\u001b[39m, training\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining)\n",
      "File \u001b[1;32me:\\llama\\work\\.conda\\lib\\site-packages\\torch_geometric\\nn\\pool\\glob.py:61\u001b[0m, in \u001b[0;36mglobal_mean_pool\u001b[1;34m(x, batch, size)\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[39mif\u001b[39;00m batch \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m     60\u001b[0m     \u001b[39mreturn\u001b[39;00m x\u001b[39m.\u001b[39mmean(dim\u001b[39m=\u001b[39mdim, keepdim\u001b[39m=\u001b[39mx\u001b[39m.\u001b[39mdim() \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m2\u001b[39m)\n\u001b[1;32m---> 61\u001b[0m \u001b[39mreturn\u001b[39;00m scatter(x, batch, dim\u001b[39m=\u001b[39;49mdim, dim_size\u001b[39m=\u001b[39;49msize, reduce\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mmean\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[1;32me:\\llama\\work\\.conda\\lib\\site-packages\\torch_geometric\\utils\\scatter.py:74\u001b[0m, in \u001b[0;36mscatter\u001b[1;34m(src, index, dim, dim_size, reduce)\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[39mif\u001b[39;00m reduce \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mmean\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m     73\u001b[0m     count \u001b[39m=\u001b[39m src\u001b[39m.\u001b[39mnew_zeros(dim_size)\n\u001b[1;32m---> 74\u001b[0m     count\u001b[39m.\u001b[39;49mscatter_add_(\u001b[39m0\u001b[39;49m, index, src\u001b[39m.\u001b[39;49mnew_ones(src\u001b[39m.\u001b[39;49msize(dim)))\n\u001b[0;32m     75\u001b[0m     count \u001b[39m=\u001b[39m count\u001b[39m.\u001b[39mclamp(\u001b[39mmin\u001b[39m\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m     77\u001b[0m     index \u001b[39m=\u001b[39m broadcast(index, src, dim)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Expected index [590] to be smaller than self [32] apart from dimension 0 and to be smaller size than src [512]"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(\"Start training...\")\n",
    "print(type(model))\n",
    "for epoch in range(1, 5):\n",
    "    print(\"====epoch \" + str(epoch))\n",
    "\n",
    "    # training\n",
    "    train(model, device, train_loader, optimizer)\n",
    "\n",
    "    # evaluating\n",
    "    train_acc = eval(model, device, train_loader)\n",
    "    val_acc = eval(model, device, val_loader)\n",
    "    print({'Train': train_acc, 'Validation': val_acc})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
