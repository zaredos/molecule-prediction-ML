{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 3\n",
    "The prediction of molecular properties is an important task in drug discovery. The molecules' atomic composition and arrangement can already tell us a lot about their biological behavior. Each 2D molecule can be represented as a graph, where the nodes are atoms connected by edges corresponding to chemical bonds. The prediction of molecular properties can be formulized as a graph classification task, and graph neural network is usually applied for making graph-level prediction.\n",
    "\n",
    "In this project, you need develop a model for predicting the toxicity of new molecules. This notebook provides a sample pipeline that establishes a baseline. It is expected that your methods should outperform this baseline. You are strongly encouraged to think about designing more powerful models, finetuning hyperparameters, developing better training strategies, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch_geometric in e:\\llama\\work\\.conda\\lib\\site-packages (2.4.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\harry\\appdata\\roaming\\python\\python310\\site-packages (from torch_geometric) (4.64.1)\n",
      "Requirement already satisfied: numpy in e:\\llama\\work\\.conda\\lib\\site-packages (from torch_geometric) (1.26.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\harry\\appdata\\roaming\\python\\python310\\site-packages (from torch_geometric) (1.10.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\harry\\appdata\\roaming\\python\\python310\\site-packages (from torch_geometric) (3.1.2)\n",
      "Requirement already satisfied: requests in c:\\users\\harry\\appdata\\roaming\\python\\python310\\site-packages (from torch_geometric) (2.28.2)\n",
      "Requirement already satisfied: pyparsing in c:\\users\\harry\\appdata\\roaming\\python\\python310\\site-packages (from torch_geometric) (3.0.9)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\harry\\appdata\\roaming\\python\\python310\\site-packages (from torch_geometric) (1.2.2)\n",
      "Requirement already satisfied: psutil>=5.8.0 in e:\\llama\\work\\.conda\\lib\\site-packages (from torch_geometric) (5.9.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\harry\\appdata\\roaming\\python\\python310\\site-packages (from jinja2->torch_geometric) (2.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\harry\\appdata\\roaming\\python\\python310\\site-packages (from requests->torch_geometric) (3.0.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\harry\\appdata\\roaming\\python\\python310\\site-packages (from requests->torch_geometric) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\harry\\appdata\\roaming\\python\\python310\\site-packages (from requests->torch_geometric) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\harry\\appdata\\roaming\\python\\python310\\site-packages (from requests->torch_geometric) (2022.12.7)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\harry\\appdata\\roaming\\python\\python310\\site-packages (from scikit-learn->torch_geometric) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\harry\\appdata\\roaming\\python\\python310\\site-packages (from scikit-learn->torch_geometric) (3.1.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\harry\\appdata\\roaming\\python\\python310\\site-packages (from tqdm->torch_geometric) (0.4.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\harry\\appdata\\roaming\\python\\python310\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\harry\\appdata\\roaming\\python\\python310\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\harry\\appdata\\roaming\\python\\python310\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\harry\\appdata\\roaming\\python\\python310\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 23.1.2 -> 23.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: rdkit-pypi in e:\\llama\\work\\.conda\\lib\\site-packages (2022.9.5)\n",
      "Requirement already satisfied: numpy in e:\\llama\\work\\.conda\\lib\\site-packages (from rdkit-pypi) (1.26.2)\n",
      "Requirement already satisfied: Pillow in c:\\users\\harry\\appdata\\roaming\\python\\python310\\site-packages (from rdkit-pypi) (9.4.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\harry\\appdata\\roaming\\python\\python310\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\harry\\appdata\\roaming\\python\\python310\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\harry\\appdata\\roaming\\python\\python310\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\harry\\appdata\\roaming\\python\\python310\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 23.1.2 -> 23.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# New these two packages\n",
    "!pip install torch_geometric\n",
    "!pip install rdkit-pypi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some tutorials.\n",
    "\n",
    "\n",
    "\n",
    "1.   Pytorch geometric package: https://pytorch-geometric.readthedocs.io/en/latest/get_started/introduction.html\n",
    "2.   PyTorch Geometric for Graph-Based Molecular Property Prediction using MoleculeNet benchmark: https://medium.com/@nikopavl4/pytorch-geometric-for-graph-based-molecular-property-prediction-using-moleculenet-benchmark-41e36369d3c6\n",
    "3. Graph neural networks for graph classification. https://colab.research.google.com/drive/1I8a0DfQ3fI7Njc62__mVXUlcAleUclnb?usp=sharing\n",
    "4. Related github repository on molecular property predictions. https://github.com/yifeiwang15/MotifConv/tree/main/MCM_for_molecule_benchmarks\n",
    "\n",
    "\n",
    "## What are node and edge features in a molecule.\n",
    "\n",
    "### Node features:\n",
    "\n",
    "**Atomic number**: Number of protons in the nucleus of an atom. It’s characteristic of a chemical element and determines its place in the periodic table.\n",
    "\n",
    "**Chirality**: A molecule is chiral if it is distinguishable from its mirror image by any combination of rotations, translations, and some conformational changes. Different types of chirality exist depending on the molecule and the arrangement of the atoms.\n",
    "\n",
    "**Degree**: Number of directly-bonded neighbors of the atom.\n",
    "Formal charge: Charge assigned to an atom. It reflects the electron count associated with the atom compared to the isolated neutral atom.\n",
    "\n",
    "**Number of H**: Total number of hydrogen atoms on the atom.\n",
    "Number of radical e: Number of unpaired electrons of the atom.\n",
    "\n",
    "**Hybridization**: Atom’s hybridization.\n",
    "\n",
    "**Is aromatic**: Whether it is included in a cyclic structure with pi bonds. This type of structure tends to be very stable in comparison with other geometric arrangements of the same atoms.\n",
    "\n",
    "**Is in ring**: Whether it is included in a ring (a simple cycle of atoms and bonds in a molecule).\n",
    "\n",
    "### Edge features:\n",
    "\n",
    "**Bond type:**: Whether the bond is single, double, triple, or aromatic.\n",
    "\n",
    "**Stereo Type:** Stereo configuration of the bond.\n",
    "\n",
    "**Is conjugated**: Whether or not the bond is considered to be conjugated.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset preparation and train-valid splitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\harry\\AppData\\Roaming\\Python\\Python310\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch_geometric\n",
    "import numpy as np\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.data import DataLoader\n",
    "from torch_geometric.datasets import MoleculeNet\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of training set: 6264\n",
      "Size of validation set: 783\n",
      "Size of test set: 784\n"
     ]
    }
   ],
   "source": [
    "# Load datasets. The training and validation sets contain both molecules and their property labels. The test set only contain molecules.\n",
    "# There are 12 property tasks for prediction. Some properties labels are missing (i.e., nan). You can ignore them.\n",
    "train_dataset = torch.load(\"train_data.pt\")\n",
    "valid_dataset = torch.load(\"valid_data.pt\")\n",
    "test_dataset = torch.load(\"test_data.pt\")\n",
    "\n",
    "print(f'Size of training set: {len(train_dataset)}')\n",
    "print(f'Size of validation set: {len(valid_dataset)}')\n",
    "print(f'Size of test set: {len(test_dataset)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can observe, we have 11 nodes (rows) and each node has 9 features (columns). However, the features provided by Moleculenet are discrete and of type long, so we need to convert them first to continuous embeddings in order to feed them in any ML model.\n",
    "\n",
    "For example, the first column indicates the atomic number of a node, where 1 represents Hydrogen, 6 represents Carbon, 8 for Oxygen, according to periodic table of elements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Atom encoder\n",
    "\n",
    "# class AtomEncoder(torch.nn.Module):\n",
    "#     def __init__(self, hidden_channels, num_node_features):\n",
    "#         super(AtomEncoder, self).__init__()\n",
    "\n",
    "#         self.embeddings = torch.nn.ModuleList()\n",
    "\n",
    "#         for i in range(num_node_features):\n",
    "#             self.embeddings.append(torch.nn.Embedding(100, hidden_channels))\n",
    "\n",
    "#     def reset_parameters(self):\n",
    "#         for embedding in self.embeddings:\n",
    "#             embedding.reset_parameters()\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         if x.dim() == 1:\n",
    "#             x = x.unsqueeze(1)\n",
    "\n",
    "#         out = 0\n",
    "#         for i in range(x.size(1)):\n",
    "#             out += self.embeddings[i](x[:, i])\n",
    "#         return out\n",
    "\n",
    "\n",
    "# # A simple graph neural network model\n",
    "\n",
    "class AtomEncoder(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels, num_node_features):\n",
    "        super(AtomEncoder, self).__init__()\n",
    "\n",
    "        self.linear_layers = torch.nn.ModuleList()\n",
    "\n",
    "        for i in range(num_node_features):\n",
    "            self.linear_layers.append(torch.nn.Linear(1, hidden_channels))\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        for linear in self.linear_layers:\n",
    "            torch.nn.init.xavier_uniform_(linear.weight)\n",
    "            torch.nn.init.zeros_(linear.bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if x.dim() == 1:\n",
    "            x = x.unsqueeze(1)\n",
    "\n",
    "        out = 0\n",
    "        for i in range(x.size(1)):\n",
    "            out += self.linear_layers[i](x[:, i:i+1])\n",
    "        return out\n",
    "\n",
    "\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.nn import global_mean_pool as gap\n",
    "import torch.nn.functional as F \n",
    "from torch.nn import Linear\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels, num_node_features, num_classes):\n",
    "        super(GCN, self).__init__()\n",
    "        torch.manual_seed(42)\n",
    "        self.emb = AtomEncoder(hidden_channels=32, num_node_features=num_node_features)\n",
    "        self.conv1 = GCNConv(hidden_channels,hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
    "        self.conv3 = GCNConv(hidden_channels, hidden_channels)\n",
    "        self.lin = Linear(hidden_channels, num_classes)\n",
    "\n",
    "    def forward(self, batch):\n",
    "        x , edge_index, batch_size = batch.x, batch.edge_index, batch.batch\n",
    "        x = self.emb(x)\n",
    "\n",
    "        # 2. Readout layer\n",
    "        x = gap(x, batch_size)  # [batch_size, hidden_channels]\n",
    "        # 3. Apply a final classifier\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.lin(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New Changes from here on out\n",
    "First, we get features that are not included and add them to the original feature datasets.<br>\n",
    "Below is some testing for each of the Descriptors in the rdkit Chem module\n",
    "\n",
    "https://www.frontiersin.org/articles/10.3389/fphar.2017.00880/full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.45\n",
      "0.7\n",
      "0.9\n"
     ]
    }
   ],
   "source": [
    "from rdkit import Chem\n",
    "from rdkit.Chem import Descriptors as desc \n",
    "\n",
    "print(desc.FpDensityMorgan1(Chem.MolFromSmiles(train_dataset[1].smiles)))\n",
    "print(desc.FpDensityMorgan2(Chem.MolFromSmiles(train_dataset[1].smiles)))\n",
    "print(desc.FpDensityMorgan3(Chem.MolFromSmiles(train_dataset[1].smiles)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptor_list = [desc.FpDensityMorgan1,\n",
    "                   desc.FpDensityMorgan2,\n",
    "                   desc.FpDensityMorgan3,\n",
    "                   desc.BalabanJ,\n",
    "                  desc.BertzCT,\n",
    "                  desc.Ipc,\n",
    "                  desc.Kappa1,\n",
    "                  desc.Kappa2,\n",
    "                  desc.Kappa3,\n",
    "                  desc.MolWt,\n",
    "                  desc.MolLogP,\n",
    "                  desc.NumRotatableBonds,\n",
    "                  desc.NumHAcceptors,\n",
    "                  desc.NumHDonors,\n",
    "                  desc.NumHeteroatoms,\n",
    "                  desc.NumValenceElectrons,\n",
    "                  desc.MolMR,\n",
    "                  desc.NumRadicalElectrons,\n",
    "                  desc.RingCount,\n",
    "                  desc.NumAromaticRings,\n",
    "                  desc.NumAliphaticRings,\n",
    "                  desc.NumSaturatedRings,\n",
    "                  desc.NumAromaticHeterocycles,\n",
    "                  desc.NumAromaticCarbocycles,\n",
    "                  desc.NumSaturatedHeterocycles,\n",
    "                  desc.NumSaturatedCarbocycles,\n",
    "                  desc.NumAliphaticHeterocycles,\n",
    "                  desc.NumAliphaticCarbocycles,\n",
    "                  desc.NOCount,\n",
    "                  desc.NHOHCount,\n",
    "                  desc.FractionCSP3,\n",
    "                  desc.LabuteASA,\n",
    "                  desc.TPSA,\n",
    "                   ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make sure none of the descriptors can give NaN as a value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\llama\\work\\.conda\\lib\\site-packages\\torch_geometric\\deprecation.py:22: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    }
   ],
   "source": [
    "# Example of preparing data loaders.\n",
    "# You can use any batch size and see what happens in model performance.\n",
    "\n",
    "from torch_geometric.data import DataLoader\n",
    "\n",
    "batch_size=32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train and eval function\n",
    "from sklearn.metrics import roc_auc_score\n",
    "def train(model, device, loader, optimizer):\n",
    "    model.train()\n",
    "\n",
    "    for step, batch in enumerate(loader):\n",
    "        batch = batch.to(device)\n",
    "        pred = model(batch)\n",
    "        y = batch.y.view(pred.shape).to(torch.float64)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        ## ignore nan targets (unlabeled) when computing training loss.\n",
    "        is_labeled = batch.y == batch.y\n",
    "        loss = criterion(pred.to(torch.float32)[is_labeled], batch.y.to(torch.float32)[is_labeled]).mean()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "def eval(model, device, loader):\n",
    "    model.eval()\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    # For every batch in test loader\n",
    "    for batch in loader:\n",
    "\n",
    "        batch = batch.to(device)\n",
    "        if batch.x.shape[0] == 1:\n",
    "            pass\n",
    "        else:\n",
    "            with torch.no_grad():\n",
    "                pred = model(batch)\n",
    "\n",
    "            y_true.append(batch.y.view(pred.shape))\n",
    "            y_pred.append(pred)\n",
    "\n",
    "    y_true = torch.cat(y_true, dim = 0).numpy()\n",
    "    y_pred = torch.cat(y_pred, dim = 0).numpy()\n",
    "    # Compute the ROC - AUC score and store as history\n",
    "    rocauc_list = []\n",
    "\n",
    "    for i in range(y_true.shape[1]):\n",
    "        #AUC is only defined when there is at least one positive data.\n",
    "        if np.sum(y_true[:,i] == 1) > 0 and np.sum(y_true[:,i] == 0) > 0:\n",
    "            # ignore nan values\n",
    "            is_labeled = y_true[:,i] == y_true[:,i]\n",
    "            rocauc_list.append(roc_auc_score(y_true[is_labeled,i], y_pred[is_labeled,i]))\n",
    "\n",
    "    if len(rocauc_list) == 0:\n",
    "        raise RuntimeError('No positively labeled data available. Cannot compute ROC-AUC.')\n",
    "\n",
    "    return {'rocauc': sum(rocauc_list)/len(rocauc_list)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== Iteration 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[22:38:28] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:38:44] WARNING: not removing hydrogen atom without neighbors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (1x320 and 1x32)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mg:\\CS149\\rand_descriptors.ipynb Cell 18\u001b[0m line \u001b[0;36m4\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/CS149/rand_descriptors.ipynb#X24sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m \u001b[39mfor\u001b[39;00m step, batch \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(train_loader):\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/CS149/rand_descriptors.ipynb#X24sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m     batch \u001b[39m=\u001b[39m batch\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/g%3A/CS149/rand_descriptors.ipynb#X24sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m     pred \u001b[39m=\u001b[39m model(batch)\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/CS149/rand_descriptors.ipynb#X24sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m     y \u001b[39m=\u001b[39m batch\u001b[39m.\u001b[39my\u001b[39m.\u001b[39mview(pred\u001b[39m.\u001b[39mshape)\u001b[39m.\u001b[39mto(torch\u001b[39m.\u001b[39mfloat32)\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/CS149/rand_descriptors.ipynb#X24sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m     optimizer\u001b[39m.\u001b[39mzero_grad()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32mg:\\CS149\\rand_descriptors.ipynb Cell 18\u001b[0m line \u001b[0;36m6\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/CS149/rand_descriptors.ipynb#X24sZmlsZQ%3D%3D?line=65'>66</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/CS149/rand_descriptors.ipynb#X24sZmlsZQ%3D%3D?line=66'>67</a>\u001b[0m     x , edge_index, batch_size \u001b[39m=\u001b[39m batch\u001b[39m.\u001b[39mx, batch\u001b[39m.\u001b[39medge_index, batch\u001b[39m.\u001b[39mbatch\n\u001b[1;32m---> <a href='vscode-notebook-cell:/g%3A/CS149/rand_descriptors.ipynb#X24sZmlsZQ%3D%3D?line=67'>68</a>\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49memb(x)\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/CS149/rand_descriptors.ipynb#X24sZmlsZQ%3D%3D?line=69'>70</a>\u001b[0m     \u001b[39m# 2. Readout layer\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/CS149/rand_descriptors.ipynb#X24sZmlsZQ%3D%3D?line=70'>71</a>\u001b[0m     x \u001b[39m=\u001b[39m gap(x, batch_size)  \u001b[39m# [batch_size, hidden_channels]\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32mg:\\CS149\\rand_descriptors.ipynb Cell 18\u001b[0m line \u001b[0;36m4\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/CS149/rand_descriptors.ipynb#X24sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m out \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/CS149/rand_descriptors.ipynb#X24sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(x\u001b[39m.\u001b[39msize(\u001b[39m1\u001b[39m)):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/g%3A/CS149/rand_descriptors.ipynb#X24sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m     out \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlinear_layers[i](x[:, i])\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/CS149/rand_descriptors.ipynb#X24sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\modules\\linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 114\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (1x320 and 1x32)"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import random\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "model = GCN(32, 10, 12)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "def calculate_descriptors(d, descriptor_list):\n",
    "    dataset = d.copy()\n",
    "    for graph in dataset:\n",
    "        mol = Chem.MolFromSmiles(graph.smiles)\n",
    "        features = []\n",
    "        for descriptor in descriptor_list:\n",
    "            value = descriptor(mol)\n",
    "            features.append(value)\n",
    "        graph.x = torch.tensor(features).to(torch.float32)\n",
    "    return dataset\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss(reduction=\"none\")\n",
    "\n",
    "# Loop for multiple iterations\n",
    "for iteration in range(10):\n",
    "    print(\"==== Iteration \" + str(iteration + 1))\n",
    "\n",
    "    # Create copies of the training and validation datasets\n",
    "    train_dataset_copy = calculate_descriptors(train_dataset, descriptor_list)\n",
    "    valid_dataset_copy = calculate_descriptors(valid_dataset, descriptor_list)\n",
    "\n",
    "    # Randomly choose 10 functions from the descriptor_list\n",
    "    random_functions = random.sample(descriptor_list, 10)\n",
    "\n",
    "    # Calculate and append descriptors for the new training and validation datasets\n",
    "    train_dataset_copy = calculate_descriptors(train_dataset_copy, random_functions)\n",
    "    valid_dataset_copy = calculate_descriptors(valid_dataset_copy, random_functions)\n",
    "\n",
    "    # Create a new model with the given parameters\n",
    "    model = GCN(32, 10, 12)\n",
    "    model.to(device)\n",
    "\n",
    "    # Start training for 10 epochs\n",
    "    for epoch in range(1, 11):\n",
    "        print(\"Epoch \" + str(epoch))\n",
    "\n",
    "        # Training\n",
    "        model.train()\n",
    "        for step, batch in enumerate(train_loader):\n",
    "            batch = batch.to(device)\n",
    "            pred = model(batch)\n",
    "            y = batch.y.view(pred.shape).to(torch.float32)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            is_labeled = batch.y == batch.y\n",
    "            loss = criterion(pred.to(torch.float32)[is_labeled], y[is_labeled]).mean()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    # Evaluate the final training and validation accuracy\n",
    "    train_acc = eval(model, device, train_loader)\n",
    "    val_acc = eval(model, device, val_loader)\n",
    "    print(\"Final Training Accuracy:\", train_acc)\n",
    "    print(\"Final Validation Accuracy:\", val_acc)\n",
    "    print(\"Functions Used:\", [str(func.__name__) for func in random_functions])\n",
    "    print(\"====================\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
